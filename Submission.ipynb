{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction\n",
    "You can simply run the following cell.\n",
    "\n",
    "But before running, please make sure that this file is located in a directory that contains *train_set_y.csv_*and *train_set_x.csv*.\n",
    "\n",
    "Also, please change the variable value of *path_to_test_set_x* to the path to the test set csv file. \n",
    "By default, it is set to *test_set_x.csv*.\n",
    "\n",
    "The final result file is named *test_set_y_final.csv*.\n",
    "\n",
    "Note: we found out that adjusting encoding of the text does not really help the accuracy but it drops the accuracy. \n",
    "Thus, we are using orthography filtering preprocessing only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def learn_y(train_set_xy):\n",
    "    # define a probability distribution data structure for theta_Y\n",
    "    est_y = {}\n",
    "    # compute probability mass function\n",
    "    n = train_set_xy['Category'].count()\n",
    "    y_counts = train_set_xy['Category'].value_counts()\n",
    "    for i in range(5):\n",
    "        est_y[i] = y_counts[i] / n\n",
    "    return est_y\n",
    "\n",
    "def learn_xy(train_set_xy):\n",
    "    xy_occurances = {}\n",
    "    for index, row in train_set_xy.iterrows():\n",
    "        y = row['Category']\n",
    "        if y not in xy_occurances:\n",
    "            xy_occurances[y] = {}\n",
    "            xy_occurances[y]['count'] = 0\n",
    "        chars = list(str(row['Text']))    \n",
    "        xy_occurances[y]['count'] = xy_occurances[y]['count'] + len(chars)   \n",
    "        for char in chars:\n",
    "            if char in xy_occurances[y]:\n",
    "                xy_occurances[y][char] = xy_occurances[y][char] + 1\n",
    "            else:\n",
    "                xy_occurances[y][char] = 1 \n",
    "                \n",
    "                \n",
    "    est_xy = {}\n",
    "    for y, counts in xy_occurances.items():\n",
    "        est_xy[y] = {}\n",
    "        for x, m in counts.items():\n",
    "            if (x != 'count'):\n",
    "                est_xy[y][x] = (m + 1) / (counts['count'] + len(counts) - 1)\n",
    "    return est_xy\n",
    "\n",
    "def classifier_multinomial_bayes_net(est_y, est_xy, test_set_x):\n",
    "    result = {}\n",
    "    for index, row in test_set_x.iterrows():\n",
    "        p_yx = {}\n",
    "        c_frequencies = {}\n",
    "        chars = list(str(row['Text']).lower().replace(\" \", \"\")) \n",
    "        # compute frequencies\n",
    "        for c in chars:\n",
    "            if c in c_frequencies:\n",
    "                c_frequencies[c] = c_frequencies[c] + 1\n",
    "            else:\n",
    "                c_frequencies[c] = 1\n",
    "        # compute probabilities\n",
    "        for y, p_y in est_y.items():\n",
    "            p_yx[y] = p_y\n",
    "            for c, frequency in c_frequencies.items():\n",
    "                if c in est_xy[y]:\n",
    "                    p_yx[y] = p_yx[y] * (est_xy[y][c] ** frequency)  \n",
    "        max_p = -1.0\n",
    "        max_y = -1\n",
    "        for y, p in p_yx.items():\n",
    "            if (max_p < p):\n",
    "                max_p = p\n",
    "                max_y = y\n",
    "        result[index] = max_y\n",
    "    return pd.DataFrame(list(result.items()), columns=['Id', 'Category'])\n",
    "\n",
    "cp1252 = {\n",
    "    # from http://www.microsoft.com/typography/unicode/1252.htm\n",
    "    u\"\\u20AC\": u\"\\x80\", # EURO SIGN\n",
    "    u\"\\u201A\": u\"\\x82\", # SINGLE LOW-9 QUOTATION MARK\n",
    "    u\"\\u0192\": u\"\\x83\", # LATIN SMALL LETTER F WITH HOOK\n",
    "    u\"\\u201E\": u\"\\x84\", # DOUBLE LOW-9 QUOTATION MARK\n",
    "    u\"\\u2026\": u\"\\x85\", # HORIZONTAL ELLIPSIS\n",
    "    u\"\\u2020\": u\"\\x86\", # DAGGER\n",
    "    u\"\\u2021\": u\"\\x87\", # DOUBLE DAGGER\n",
    "    u\"\\u02C6\": u\"\\x88\", # MODIFIER LETTER CIRCUMFLEX ACCENT\n",
    "    u\"\\u2030\": u\"\\x89\", # PER MILLE SIGN\n",
    "    u\"\\u0160\": u\"\\x8A\", # LATIN CAPITAL LETTER S WITH CARON\n",
    "    u\"\\u2039\": u\"\\x8B\", # SINGLE LEFT-POINTING ANGLE QUOTATION MARK\n",
    "    u\"\\u0152\": u\"\\x8C\", # LATIN CAPITAL LIGATURE OE\n",
    "    u\"\\u017D\": u\"\\x8E\", # LATIN CAPITAL LETTER Z WITH CARON\n",
    "    u\"\\u2018\": u\"\\x91\", # LEFT SINGLE QUOTATION MARK\n",
    "    u\"\\u2019\": u\"\\x92\", # RIGHT SINGLE QUOTATION MARK\n",
    "    u\"\\u201C\": u\"\\x93\", # LEFT DOUBLE QUOTATION MARK\n",
    "    u\"\\u201D\": u\"\\x94\", # RIGHT DOUBLE QUOTATION MARK\n",
    "    u\"\\u2022\": u\"\\x95\", # BULLET\n",
    "    u\"\\u2013\": u\"\\x96\", # EN DASH\n",
    "    u\"\\u2014\": u\"\\x97\", # EM DASH\n",
    "    u\"\\u02DC\": u\"\\x98\", # SMALL TILDE\n",
    "    u\"\\u2122\": u\"\\x99\", # TRADE MARK SIGN\n",
    "    u\"\\u0161\": u\"\\x9A\", # LATIN SMALL LETTER S WITH CARON\n",
    "    u\"\\u203A\": u\"\\x9B\", # SINGLE RIGHT-POINTING ANGLE QUOTATION MARK\n",
    "    u\"\\u0153\": u\"\\x9C\", # LATIN SMALL LIGATURE OE\n",
    "    u\"\\u017E\": u\"\\x9E\", # LATIN SMALL LETTER Z WITH CARON\n",
    "    u\"\\u0178\": u\"\\x9F\", # LATIN CAPITAL LETTER Y WITH DIAERESIS\n",
    "}\n",
    "\n",
    "slovak = {'á','ä','č','ď','é','í','ĺ','ľ','ň','ó','ô','ŕ','š','ť','ú','ý','ž'}\n",
    "german = {'ü', '»', '‚', '…', '“', '‹', 'ö', '‘', '–', 'ß', '—', '«', 'ä', '›', '„'}\n",
    "spanish = {'ñ','á','é','í','ó','ú','ü','¿','¡','«','»','“','”','‘','’','—','–','…'}\n",
    "french = {'à','â','ç','é','è','ê','ë','î','ï','ô','œ','ù','û','ü','ÿ','«','“','”','—','»','–','’','…'}\n",
    "polish = {'ą','ć','ę','ł','ń','ó','ś','ź','ż','„','“','‚','‘','»','«','―','–','…'}\n",
    "alphabet = {'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','.',',','!','?','\"', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "orthographies = slovak.union(german).union(spanish).union(french).union(polish).union(alphabet)\n",
    "\n",
    "def is_valid_char(c):\n",
    "    return c in orthographies\n",
    "\n",
    "def doubledecode(s, as_unicode=True):\n",
    "    s = s.decode('utf8')\n",
    "    # remove the windows gremlins O^1\n",
    "    for src, dest in cp1252.items():\n",
    "        s = s.replace(src, dest)\n",
    "    s = s.encode('raw_unicode_escape')\n",
    "    if as_unicode:\n",
    "        # return as unicode string\n",
    "        s = s.decode('utf8', 'ignore')\n",
    "    return s\n",
    "\n",
    "def pre_process_train_set_of_only():\n",
    "    train_set_y = pd.read_csv('train_set_y.csv')\n",
    "    train_set_x = pd.read_csv('train_set_x.csv')\n",
    "    train_set_xy = train_set_x.set_index('Id').join(train_set_y.set_index('Id'))\n",
    "    for index, row in train_set_xy.iterrows():\n",
    "        line = \"\".join(list(filter(lambda c: is_valid_char(c), list(str(row['Text'])))))\n",
    "        train_set_xy.set_value(index, 'Text', line)\n",
    "    return train_set_xy\n",
    "\n",
    "def pre_process_test_set_of_only(filepath):\n",
    "    test_set_x = pd.read_csv(filepath)\n",
    "    for index, row in test_set_x.iterrows():\n",
    "        line = \"\".join(list(filter(lambda c: is_valid_char(c), list(str(row['Text'])))))\n",
    "        test_set_x.set_value(index, 'Text', line)\n",
    "    return test_set_x\n",
    "\n",
    "path_to_test_set_x = 'test_set_x.csv' # Give it a path to your test set file\n",
    "train_set_xy = pre_process_train_set_of_only()\n",
    "est_y = learn_y(train_set_xy)\n",
    "est_xy = learn_xy(train_set_xy)\n",
    "test_set_x = pre_process_test_set_of_only(path_to_test_set_x)\n",
    "result = classifier_multinomial_bayes_net(est_y, est_xy, test_set_x)\n",
    "result.to_csv('test_set_y_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
